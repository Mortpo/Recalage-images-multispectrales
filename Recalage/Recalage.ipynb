{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script de recalage d'image\n",
    "Script pour recaler les images, paramètre ( chemin des images, les matrices des caméras, les caméras)\n",
    "Renvoie une image recalé avec toutes les images combiné\n",
    "## Première phase\n",
    "Récupération des images à traiter\n",
    "Variable global avec le nom des caméras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../DataSet/DAMAV_Jeux_Image/SET1/Image-000003_Camera1_2019-07-30_08-48-15-832541.bmp', '../DataSet/DAMAV_Jeux_Image/SET1/Image-000003_Camera2_2019-07-30_08-48-14-239599.bmp', '../DataSet/DAMAV_Jeux_Image/SET1/Image-000003_Camera3_2019-07-30_08-48-11-852455.bmp', '../DataSet/DAMAV_Jeux_Image/SET1/Image-000003_Camera4_2019-07-30_08-48-14-493286.bmp']\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import SimpleITK as sitk\n",
    "import sys\n",
    "import glob\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm.notebook import tqdm,trange\n",
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "Cameras = (\"Camera1\",\"Camera2\",\"Camera3\",\"Camera4\")\n",
    "setImages = \"SET1\"\n",
    "CHEMINSET = os.path.join(\"..\",\"DataSet\",\"DAMAV_Jeux_Image\",setImages)\n",
    "cheminimage = os.path.join(CHEMINSET,\"*.bmp\")\n",
    "CHEMINIMAGES = sorted(glob.glob(cheminimage))\n",
    "print(CHEMINIMAGES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase deux\n",
    "Chargement des matrices des caméras\n",
    "Renvoie un dictionnaire avec comme clé le nom de la caméra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Camera1': {'mtx': array([[2.82568740e+03, 0.00000000e+00, 1.26325100e+03],\n",
      "       [0.00000000e+00, 2.82586067e+03, 9.79291096e+02],\n",
      "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]]), 'dist': array([[-0.21907795,  0.25332612,  0.00183203, -0.00175609, -0.40434549]])}, 'Camera2': {'mtx': array([[2.83125446e+03, 0.00000000e+00, 1.24208969e+03],\n",
      "       [0.00000000e+00, 2.82734145e+03, 1.06670254e+03],\n",
      "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]]), 'dist': array([[-2.16438861e-01,  3.86212514e-01, -4.21971083e-04,\n",
      "        -2.88079811e-03, -8.87713469e-01]])}, 'Camera3': {'mtx': array([[2.81720047e+03, 0.00000000e+00, 1.21782943e+03],\n",
      "       [0.00000000e+00, 2.81664248e+03, 1.00075666e+03],\n",
      "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]]), 'dist': array([[-0.18495925, -0.08103933,  0.00156822, -0.00254917,  0.64169507]])}, 'Camera4': {'mtx': array([[2.82158355e+03, 0.00000000e+00, 1.29136666e+03],\n",
      "       [0.00000000e+00, 2.82303501e+03, 1.06018449e+03],\n",
      "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]]), 'dist': array([[-0.20440932,  0.11173389,  0.00174389, -0.00086826,  0.04111568]])}}\n"
     ]
    }
   ],
   "source": [
    "cheminParam =[]\n",
    "regex = os.path.join(\"Calibration\",\"**\",\"*.npz\")\n",
    "cheminParam = sorted(glob.glob(regex,recursive=True))\n",
    "\n",
    "paramCam = dict()\n",
    "for cam in Cameras:\n",
    "    for fichierParam in cheminParam:\n",
    "        if cam in fichierParam:\n",
    "            with np.load(fichierParam) as data:\n",
    "                paramCam[cam] = {\"mtx\" : data['mtx'],\"dist\" : data['dist']}\n",
    "print(paramCam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase trois\n",
    "Correction des images pour le recalage\n",
    "Renvoie la zone d'interet (image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37abac996a70402e83bc94d98b08fae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def undistordImage(image:str,Cameras:tuple,paramCam:dict):\n",
    "\n",
    "    for cam in Cameras:\n",
    "        if cam in image:\n",
    "            mtx = paramCam[cam][\"mtx\"]\n",
    "            dist = paramCam[cam][\"dist\"]\n",
    "            img = cv2.imread(image)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            h,  w = img.shape[:2]\n",
    "            \n",
    "            newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1.0, (w,h))\n",
    "            # undistort\n",
    "            undistorded = cv2.undistort(img, mtx, dist, None, newcameramtx)\n",
    "            # crop the image\n",
    "            x, y, w, h = roi\n",
    "            roiundistorded = undistorded[y:y+h, x:x+w]\n",
    "            roiundistorded = cv2.resize(roiundistorded,(2567, 1893),cv2.INTER_CUBIC)\n",
    "            #cv2.imwrite(\"undistord\"+cam+\".bmp\",undistorded)\n",
    "            return roiundistorded\n",
    "\n",
    "undistordedImg = Parallel(n_jobs=4,prefer=\"threads\")(delayed(undistordImage)(CHEMINIMAGES[i],Cameras,paramCam)for i in tqdm(range(len(CHEMINIMAGES))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase quatre\n",
    "Definition de la metrique pour le recalage et de la fonction de recalage\n",
    "Elle focntionne en parallèle avec joblib\n",
    "Renvoie une image recalée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeMetric(fixed,moving):\n",
    "    # First, set up \"phony\" registration\n",
    "\n",
    "    R = sitk.ImageRegistrationMethod()\n",
    "    R.SetOptimizerAsGradientDescentLineSearch(learningRate=1.0,numberOfIterations=1,convergenceMinimumValue=1e-5,convergenceWindowSize=5)\n",
    "    R.SetInitialTransform(sitk.Transform(2,sitk.sitkIdentity)) # Transformation deliberately not using any initializer\n",
    "    R.SetInterpolator(sitk.sitkLinear)\n",
    "\n",
    "    #second, choose metric\n",
    "    R.SetMetricAsMeanSquares()\n",
    "\n",
    "    #third, get the metric value\n",
    "    print(R.MetricEvaluate(fixed, moving))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def RecalageOpenCV(imageRef: any ,imageToAligned: any ,saveName:str):\n",
    "    # Convert to grayscale.\n",
    "    \n",
    "    height, width = imageRef.shape\n",
    "    \n",
    "    # Create ORB detector with 5000 features.\n",
    "    orb_detector = cv2.ORB_create(5000)\n",
    "\n",
    "    # Find keypoints and descriptors.\n",
    "    # The first arg is the image, second arg is the mask\n",
    "    #  (which is not required in this case).\n",
    "    \n",
    "    kp1, d1 = orb_detector.detectAndCompute(imageToAligned, None)\n",
    "    kp2, d2 = orb_detector.detectAndCompute(imageRef, None)\n",
    "\n",
    "    \n",
    "    # Match features between the two images.\n",
    "    # We create a Brute Force matcher with\n",
    "    # Hamming distance as measurement mode.\n",
    "    matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck = True)\n",
    "    \n",
    "    # Match the two sets of descriptors.\n",
    "    matches = matcher.match(d1, d2)\n",
    "    \n",
    "    # Sort matches on the basis of their Hamming distance.\n",
    "    matches = sorted (matches,key = lambda x: x.distance)\n",
    "    \n",
    "    # Take the top 90 % matches forward.\n",
    "    matches = matches[:int(len(matches)*0.9)]\n",
    "    no_of_matches = len(matches)\n",
    "    \n",
    "    # Define empty matrices of shape no_of_matches * 2.\n",
    "    p1 = np.zeros((no_of_matches, 2))\n",
    "    p2 = np.zeros((no_of_matches, 2))\n",
    "    \n",
    "    for i in range(len(matches)):\n",
    "        p1[i, :] = kp1[matches[i].queryIdx].pt\n",
    "        p2[i, :] = kp2[matches[i].trainIdx].pt\n",
    "    \n",
    "\n",
    "    # Find the homography matrix.\n",
    "    homography, mask = cv2.findHomography(p1, p2, cv2.RANSAC)\n",
    "    # Use this matrix to transform the\n",
    "    # colored image wrt the reference image.\n",
    "    transformed_img = cv2.warpPerspective(imageToAligned,\n",
    "                        homography, (width, height))\n",
    "\n",
    "    computeMetric(sitk.GetImageFromArray(np.float32(imageToAligned))  ,sitk.GetImageFromArray(np.float32(transformed_img)))\n",
    "\n",
    "    # Save the output.\n",
    "    #cv2.imwrite(saveName, transformed_img)\n",
    "    return transformed_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1946.2581406782126\n",
      "396.94857378515684\n",
      "2382.000613253141\n"
     ]
    }
   ],
   "source": [
    "output = (\"outV10.jpg\",\"outV20.jpg\",\"outV30.jpg\")\n",
    "\n",
    "homography = Parallel(n_jobs=4,prefer=\"threads\")(delayed(RecalageOpenCV)(undistordedImg[0],undistordedImg[i],output[i-1])for i in range(1,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase cinq\n",
    "Prend les images et les traites pour avoir une image recalé finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = []\n",
    "for imageRecale in homography:\n",
    "    images.append(imageRecale)\n",
    "images.append(undistordedImg[0])\n",
    "\n",
    "zeros = np.zeros((images[0].shape),dtype= \"uint8\" )\n",
    "\n",
    "mask = []\n",
    "for imageRecale in images:\n",
    "    mask.append(cv2.compare(imageRecale,zeros,cv2.CMP_EQ))\n",
    "\n",
    "fusion = zeros\n",
    "for i in range(0,len(mask)):\n",
    "    fusion = cv2.bitwise_or(mask[i],fusion)\n",
    "masks = cv2.bitwise_not(fusion)\n",
    "\n",
    "imagemasked = []\n",
    "for imgeRecale in images:\n",
    "    imagemasked.append(cv2.bitwise_and(imgeRecale,masks))\n",
    "\n",
    "#cv2.imwrite(\"mask.jpg\",masks)\n",
    "end = cv2.merge(imagemasked)\n",
    "cv2.imwrite(setImages+\"outcolor.jpg\",end)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "24bbd6f9d8d5bf7758940204837a24acf0a65ad83c922a3aac9a0e3a55019435"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('DeepL': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
